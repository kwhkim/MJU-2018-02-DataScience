---
title: "Artificial Neural Network"
author: "김권현"
date: "2018년 12월 7일"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 인공신경망(ANN; Artificial Neural Network)

## 가장 기본적인 3층 인공신경망

$$h_k(x_1, x_2, \cdots, x_P) = \text{sigmoid} \left(\beta_{k0} + \sum_{j=1}^P \beta_{kj}x_j \right)$$

$$ f(x_1, x_2, \cdots, x_P) = \gamma_0 + \sum_{j=1}^H \gamma_j h_j$$

- $P$: 예측변수의 갯수, $H$: 히든노드의 갯수, $h_k$: $k$-번째 히든노드의 출력, $f$: 최종 출력 함수.

- 전체 모수(parameter)의 갯수 = $H(P+1)+H+1$

* 학습에 영향을 주는 요인들
    - 손실 함수 : $SSE = \sum_{i} (y_i - f(x_i1, x_i2, \cdots, x_iP))^2$
    - 모수 초기화 
    - 모수 최적화 
        - 경사 하강법(Gradient Descent Algorithm) : 역전파(Backpropagation) 알고리즘
        
* 인공신경망을 구성하는 요소
    - 입력층(input layer)
    - 노드 사이의 연결 구조 
        - FCN(Fully Connected Network) 
        - CNN(Convolutional Neural Network)
    - 활성화 함수(activation function)
    - 출력층(output layer)
    
* 예: [텐서플로우 놀이터](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.18148&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)

* 인공신경망의 장점
    - 상호작용과 비선형성을 모형화할 수 있다.
    - UFA(Universal Function Approximation)이 가능하다.

* 인공신경망의 단점
    - 과적합이 되기 쉽다.
    - 전역 최적점을 찾기 어렵다.
  

## 구현 1 : `nnet::nnet`, `caret::avNNet`

```{r NN, eval=F}
nnet
caret::avNNet

train(method='nnet')
train(method='avNNet')
```

## 구현 2 : `keras`

* [설치](https://keras.rstudio.com/)

```{r, eval=F}
install.packages('keras')
library(keras)
install_keras()
```





   